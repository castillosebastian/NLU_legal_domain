{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU_Semantica_Vectoria_II.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBvt06MZ5VoGPigfs85G5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castillosebastian/NLU_legal_domain/blob/master/NLU_Semantica_Vectoria_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOC9tzHzBjD"
      },
      "source": [
        "# Semantica Vectorial para procesar sentencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6lhCPvQ5kxw"
      },
      "source": [
        "# Libraries, tools and thanks \n",
        "import bs4\n",
        "import nltk\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "from google.colab import drive\n",
        "import numpy as np \n",
        "import json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUuIZYyKxsk"
      },
      "source": [
        "# procesar con GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJAxQeOi3eRz",
        "outputId": "c0084fee-b8c8-4023-d7dc-73fd05ae7287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_qSVGUt4ASA",
        "outputId": "fb6a5a8f-905f-4d8b-83bd-6d1d9d59f8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd  'drive/My Drive/Colab Notebooks/data'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnDT50z377Nk",
        "outputId": "77ecb61b-2f40-4d8c-98b3-fb68501a74ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus_fallosmetdat.json  tbdoctrina.json  tbmetdat.json\n",
            "corpus_textosfallos.json  tbfallos.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFTywqxn3_mA"
      },
      "source": [
        "# Lectura de tablas de datos primarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAA71S5CxjmW"
      },
      "source": [
        "with open('tbfallos.json', 'r') as myfile:\n",
        "    data1=myfile.read()\n",
        "# parse file\n",
        "tbfallos = json.loads(data1)\n",
        "tbfallos = pd.DataFrame.from_dict(tbfallos)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIHXCKCM6Rfd"
      },
      "source": [
        "tbfallos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zik8UJ2cDrxh"
      },
      "source": [
        "# Instalar librería STANZA (Stanford NLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYLU44dfhNd"
      },
      "source": [
        "! pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oS1AodfhBK_",
        "outputId": "92969643-9a01-48fc-a85e-1406ddf56348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import stanza\n",
        "stanza.download('es') # download spanish model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 20.3MB/s]                    \n",
            "2020-10-27 20:28:33 INFO: Downloading default packages for language: es (Spanish)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/es/default.zip: 100%|██████████| 583M/583M [03:03<00:00, 3.17MB/s]\n",
            "2020-10-27 20:31:44 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RyZsHEz5taT"
      },
      "source": [
        "# Prueba de Tokenizacion de un sumario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqUZEfmU7s1-"
      },
      "source": [
        "fallos = tbfallos['textos_fallo'][1]\n",
        "fallos = fallos.replace(\"#\",\"\\n\\n\")\n",
        "#fallos = fallos.values.tolist()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDHfX3Ld8Ndh",
        "outputId": "9eb5758e-f254-49ff-e0b7-55d5be3f490f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "nlp = stanza.Pipeline(lang='es', processors='tokenize,ner,mwt,pos,lemma,depparse', tokenize_no_ssplit=True)\n",
        "doc = nlp(fallos)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 20:33:30 INFO: Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| mwt       | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "| ner       | conll02 |\n",
            "=======================\n",
            "\n",
            "2020-10-27 20:33:30 INFO: Use device: gpu\n",
            "2020-10-27 20:33:30 INFO: Loading: tokenize\n",
            "2020-10-27 20:33:40 INFO: Loading: mwt\n",
            "2020-10-27 20:33:40 INFO: Loading: pos\n",
            "2020-10-27 20:33:41 INFO: Loading: lemma\n",
            "2020-10-27 20:33:41 INFO: Loading: depparse\n",
            "2020-10-27 20:33:42 INFO: Loading: ner\n",
            "2020-10-27 20:33:43 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4NRYg4SA1h5",
        "outputId": "24a2876c-c615-437e-d614-6abdbe7cd812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "doc.sentences[0].text"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TEXTO COMPLETO'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbhldXImDMaq"
      },
      "source": [
        "for sent in doc.sentences:\n",
        "    print(sent.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKvaRH-r7e3P"
      },
      "source": [
        "for i, sentence in enumerate(doc.sentences):\n",
        "    print(f'====== Sentence {i+1} tokens =======')\n",
        "    print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VUGkMho9QC9"
      },
      "source": [
        "dicts = doc.to_dict() # dicts is List[List[Dict]], representing each token / word in each sentence in the document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnJS3EU9wsEU"
      },
      "source": [
        "# Prueba de manipulacion de objeto \"doc\" sobre un sumario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bSrAtGCwv9q"
      },
      "source": [
        "def print_doc_info(doc):\n",
        "    print(f\"Num sentences:\\t{len(doc.sentences)}\")\n",
        "    print(f\"Num tokens:\\t{doc.num_tokens}\")\n",
        "    print(f\"Num words:\\t{doc.num_words}\")\n",
        "    print(f\"Num entities:\\t{len(doc.entities)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u82GFYTPw7Bp",
        "outputId": "373edc94-e7d9-48c2-ba51-95178aaf0b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "print_doc_info(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num sentences:\t47\n",
            "Num tokens:\t2008\n",
            "Num words:\t2013\n",
            "Num entities:\t92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PB5pfLyJ0s"
      },
      "source": [
        "def word_info_df(doc):\n",
        "    \"\"\"\n",
        "    - Parameters: doc (a Stanza Document object)\n",
        "    - Returns: A Pandas DataFrame object with one row for each token in\n",
        "      doc, and columns for text, lemma, upos, and xpos.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for sentence in doc.sentences:\n",
        "        for word in sentence.words:\n",
        "            row = {\n",
        "                \"text\": word.text,\n",
        "                \"lemma\": word.lemma,\n",
        "                \"upos\": word.upos,\n",
        "                \"xpos\": word.xpos,\n",
        "            }\n",
        "            rows.append(row)\n",
        "    return pd.DataFrame(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK6DdBNH1w_3"
      },
      "source": [
        "word_info_df(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYvkAKg349PH",
        "outputId": "bde2b7ab-62ca-44ff-96b7-f287d93d6170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "doc.num_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCxAr3Be1-lz",
        "outputId": "49ad2c66-aade-4f79-a596-6f29adca23fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "doc.num_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WxzLZ7s7EIr"
      },
      "source": [
        "# Prueba sobre entidades de un sumario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf3V9fPq8Yxm"
      },
      "source": [
        "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl0TWNSm78re"
      },
      "source": [
        "# select person entities\n",
        "def select_person_entities(doc):\n",
        "    return [ent for ent in doc.entities if ent.type == \"PER\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbdE-9Hn7Hda"
      },
      "source": [
        "def person_df(doc):\n",
        "    \"\"\"\n",
        "    - Parameters: doc (a Stanza Document object)\n",
        "    - Returns: A Pandas DataFrame with one row for each entity in doc\n",
        "      that has a \"PERSON\" type, and and columns text, type, start_char.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    persons = select_person_entities(doc)\n",
        "    for person in persons:\n",
        "        row = {\n",
        "            \"text\": person.text,\n",
        "            \"type\": person.type,\n",
        "            \"start_char\": person.start_char,\n",
        "            \"end_char\": person.end_char\n",
        "        }\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4NnhD1U7T4p"
      },
      "source": [
        "person_df(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDw6HEMjDJ5S"
      },
      "source": [
        "## Pruebas de manipulacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6j0xU19DHBu"
      },
      "source": [
        "for i, sent in enumerate(doc.sentences):\n",
        "  sent.print_tokens()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu7DkZlcDHB2"
      },
      "source": [
        "# Iterate over all tokens in all sentences\n",
        "for i, sent in enumerate(doc.sentences):    \n",
        "    for t in sent.tokens:\n",
        "        print(t.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BciQ23WnDHB4"
      },
      "source": [
        "# Iterate over all words in all sentences\n",
        "for i, sent in enumerate(doc.sentences):    \n",
        "    for w in sent.words:\n",
        "        print(w.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONzDqVIDHB6"
      },
      "source": [
        "# Iterate over all entities in all sentences\n",
        "for i, sent in enumerate(doc.sentences):    \n",
        "    for e in sent.entities:\n",
        "        print(e.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyE2CNGmDHB8"
      },
      "source": [
        "# Iterate over all llemmas in all sentences\n",
        "for i, sent in enumerate(doc.sentences):    \n",
        "    for w in sent.words:\n",
        "        print(w.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-99uA8e7w32o"
      },
      "source": [
        "# Prueba de Vectorizacion de un Sumario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WST5b7NcxbYa"
      },
      "source": [
        "def print_doc_info(doc):\n",
        "    print(f\"Num sentences:\\t{len(doc.sentences)}\")\n",
        "    print(f\"Num tokens:\\t{doc.num_tokens}\")\n",
        "    print(f\"Num words:\\t{doc.num_words}\")\n",
        "    print(f\"Num entities:\\t{len(doc.entities)}\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGjL4aCPxbY4",
        "outputId": "827a4192-ec8e-4d39-986b-4bff8474f434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print_doc_info(doc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num sentences:\t47\n",
            "Num tokens:\t2008\n",
            "Num words:\t2013\n",
            "Num entities:\t92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMjiMQrxl1T",
        "outputId": "ce4b5917-8334-46b3-90b1-199f1570d842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(*[f'{word.lemma}' for sent in doc.sentences for word in sent.words])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "texto completo a c U e R D o en el ciudad de el Plata , a 15 de mayo de 2019 , haber él establecer , de conformidad con él dispuesto en el Acuerdo 2078 , que deber observar él el siguiente orden de votación : doctor Soria , de Lázzari , Genoud , Kogan , él reunir el señor Jueces de el Suprema Corte de Justicia en acuerdo ordinario para pronunciar sentencia definitivo en el causa C. 122321 , \" F. , R. . Determinación de el capacidad jurídico \" . a N T e C e D e N T e S el Sala I de el Cámara de Apelación en él Civil y Comercial de San Isidro confirmar el fallo de primero instancia que , en el auto sobre determinación de el capacidad jurídico del señor R. F. , resolver aprobar el rendición de cuenta efectuado por el Curaduría Oficial de Alienados ( v. fs . 689 y 660 , respectivamente ) . él interponer , por el titular de el Asesoría de Incapaces n° 2 departamental , recurso extraordinario de inaplicabilidad de ley ( v. fs . 705/711 ) . oído el señor Procurador General , dictado el providencia de auto y encontrar él el causa en estado de pronunciar sentencia , el Suprema Corte resolver plantear y votar el siguiente C U e S T I Ó N ¿ ser fundado el recurso extraordinario de inaplicabilidad de ley ? V o T a C I Ó N a el cuestión planteado , el señor Juez doctor Soria decir : I . en el marco del proceso judicial por determinación de el capacidad jurídico del señor R. F. , en trámite ante el Juzgado de Familia n° 4 de San Isidro , el titular de el Curaduría Oficial de Alienados de San Isidro y Zárate-Campana acompañar uno rendición de cuenta informar el movimiento y saldo de el contar de Autos y de el contar Fiscal de Curaduría , adjuntar comprobante para acreditar el gasto efectuado para el sostenimiento del causante e informar el monto y erogación originado en el subsidio ley 10315 , para el caso de que el señor F. estar gozar del mismo ( v. fs . 541/548 ) . el Asesora de Incapaces impugnar el rendición de cuenta efectuado , esgrimir que de el documentación acompañado junto a el mismo surgir dos factura de el acompañante terapéutico - Daniela Elizabeth Ferreyra - en concepto de honorario por trámite de afiliación al Programa Federal de Salud ( PROFE-Salud ) , emitido con fecha 11 de noviembre de 2015 y 15 de enero de 2016 por el suma de $720 y $ 800 , respectivamente ( v. fs . 566 ) . manifestar que de el compulsa del expediente surgir que desde el año 2013 , luego de que el señor F. egresar con uno permiso de salida del Hospital Cabred , no él haber tener noticia del mismo , existir además constancia de el búsqueda de su paradero ( v. fs . 566 ) . hacer referencia a el resolución 578/03 y 127/06 en cuanto regular el necesidad de intervención de el acompañante terapéutico , aspecto sobre el que deber trabajar , etcétera , y el obligación de el curador de informar al juez él presupuestado mensualmente para gasto ordinario ( v. fs . 566 vta. ) , puntualizar que en el constancia de auto no haber elemento que indicar el actividad desplegado por el acompañante Ferreyra en él que hacer a el función e incumbencia profesional , así como tampoco documentación que respaldar el gestión y trámite facturado por dicho profesional , máxime tener en cuenta que él desconocer el paradero del señor F. ( v. fs . 567 ) . solicitar que él brindar explicación respecto de el punto señalado en el impugnación , para cuyo fin proponer el realización de uno audiencia ante el juez ( v. fs . 567 y vta . ) . frente a dicho planteo , el Juzgado disponer el pase de el actuación a el Curaduría Oficial de Alienados a fin de que él expidar al respecto ( v. fs . 568 ) . el titular de el Curaduría contestar el impugnación y solicitar el aprobación de rendición efectuado ( v. fs . 597/599 vta . ) . allí , referir que el persona con padecimiento mental ser beneficiario de uno pensión contributivo a el que él él practicar uno descuento mensual del Programa Federal de Salud cuyo afiliación no ser automático , por él que el persona comenzar a pagar por uno servicio de salud que no recibir hasta tanto él concluir el trámite y pasar a figurar como activo en el padrón . aducir que desde el Curaduría él haber generar uno operatoria para suplir el falta de afiliación automático , ser el acompañante terapéutico quien concurrir a el Delegación del PROFE al final de uno recorrido previo que deber realizar para conseguir todo el documentación necesario ( v. fs . 598 ) . asimismo , hacer referencia a el cuestión vinculado con el disponibilidad de el recurso con el que contar el organismo y controvertir por inadecuado el normativa citado por el Asesora impugnante ( v. fs . 599 ) . el Juzgado resolver , sin perjuicio de el impugnación realizado , aprobar por único vez en cuanto haber lugar por derecho el rendición de cuenta efectuado en el término y con el alcance manifestado a fs . 548 . asimismo , hacer saber a el Curaduría Oficial que deber acreditar en auto el trámite realizado en favor del causante por el cual él presentar el factura y el resultado de el mismo . además , señalar que en él sucesivo y para futuro rendición de cuenta él deber denunciar en el causa el disposición de el Suprema Corte que autorizar a el Curaduría Oficial a tercerizar el gestión de trámite , señalar que , al asignar él uno acompañante terapéutico a alguno justiciable , él deber denunciar en el respectivo auto cual ser su tarea y el procedimiento para su designación ( v. fs . 600 ) . II . apelado dicho pronunciamiento por el Asesora interviniente ( v. fs . 633 ) , el Sala I de el Cámara de Apelación él confirmar ( v. fs . 689 y vta . ) . III . contra dicho fallo él alzar el Asesora mencionado mediante recurso extraordinario de inaplicabilidad de ley , denunciar el violación de el arts . 18 , 75 inc . 22 y 23 de el Constitución nacional ; 8 de el Convención Americana sobre el Derechos Humanos ; 1 , 2 , 4 , 5 , 12 , 13 de el Convención sobre el Derechos de el persona con Discapacidad ( ley 26378 y 27044 ) ; XVII , XVIII de el Declaración Americana de el Derechos y Deberes del Hombre ; 8 de el Declaración Universal de Derechos Humanos ; 10 , 15 , 36.5 y 171 de el Constitución provincial ; 3 , 130 , 131 , 134 , 858 , 860 inc. \" c \" , 862 , 1716 , 1717 , 1766 , 1775 , 1776 del Código Civil y Comercial y 1 , 2 y 4 de el ley 26944 . asimismo , denuncia absurdo ( v. fs . 705/711 ) . sostener que el solo afirmación de el Cámara de que el explicación brindado por el Curaduría Oficial resultar razonable , sin abordar ninguno de el defensa planteado , constituir uno típico ejercicio de formulación dogmático y uno decisión arbitrario ( v. fs . 709 ) . exponer que en el fallo impugnado él ignorar todo y cada uno de el elemento obrante en el causa , el acción instado , en particular uno investigación criminal sobre el hecho , todo él que imponer el rechazo de el cuenta ( v. fs . 708 vta. ) . Controvierte que para fundamentar normativamente el sentencia y concluir en el razonabilidad de el explicación brindado por el Curaduría Oficial , el Cámara invocar el Convención sobre el Derechos de el persona con Discapacidad y a partir de el mismo pondere y calificar el gasto y el contratación efectuado como razonable ( v. fs . 710 y vta . ) . IV . el recurso deber prosperar . compartir y hacer propio el fundamento y conclusión vertido por el señor Procurador General en su dictamen de fs . 782787 , el que estimar abastecer adecuadamente el respuesta que caber brindar en el sub lite ( conf . causa C. 113234 , sent. de 9-V-2012 ; C. 115708 , sent. de 12-VI-2013 ; C. 121104 , sent. de 23-V-2017 ; C. 121980 \" P. , S \" , sent. de 27-vI-2018 ) , en cuanto señalar \" ..lo ausencia de el razón o motivo por el cual él receptar como base de el decisión , el manifestación de el Curaduría Oficial ... \" ( fs . 784 vta . ) . en efecto , el Tribunal de Alzada , como único sustento de su decisión de tener por razonable el explicación brindado por el Curaduría Oficial y mantener el providencia que aprobar el rendición de cuenta impugnado , aludir a el Convención sobre el Derechos de el persona con Discapacidad y su Protocolo Facultativo \" ...en cuanto establecer el criterio por el cual el procedimiento deber ser ajustar de manera de facilitar el realización de el trámite ... \" ( fs . 689 vta . ) . tal como denunciar el recurrente ( v. fs . 710 vta./711 ) , el genérico apreciación formulado en el fallo impugnado , además de no cumplir con el mandato convencional que exigir atención especial de el persona con discapacidad , manejo transparente con rendición de cuenta documentado , preciso y detallado , justificado en necesidad concreto y verificable , no él corresponder con el hecho acreditado en el causa , máxime cuando - como venir denunciar el Asesora de Incapaces - en el rendición de cuenta presentado por el Curaduría Oficial , él incluir gasto para el contratación de quien ser el acompañante terapéutico para realizar gestión y tramitación en favor del señor F. , facturado en noviembre de 2015 y enero de 2016 , cuando el causante mantener paradero desconocido para todo el órgano judicial desde julio de 2013 ( v. fs . 566 , 635 , 655 vta . , 707 ) . IV . en virtud de él expuesto , corresponder hacer lugar al recurso extraordinario de inaplicabilidad de ley interpuesto , revocar el fallo impugnado y devolver el auto al Tribunal de origen para que , con el debido integración , dictar uno nuevo pronunciamiento ( art . 289 , CPCC ) . el costa él imponer por su orden , dar el índole de el tema debatido ( art. 68 , segundo párrafo , CPCC ) . el presente él notificar con copia del dictamen de fs . 782787 . voto por el afirmativo . el señor Jueces doctor de Lázzari y Genoud y el señora Jueza doctora Kogan , por el mismo fundamento del señor Juez doctor Soria , votar también por el afirmativo . con él que terminar el acuerdo , dictar él el siguiente S e N T e N C I A por él expuesto en el acuerdo que anteceder , de conformidad con él dictaminado por el señor Procurador General , él hacer lugar al recurso extraordinario de inaplicabilidad de ley interpuesto , él revocar el fallo impugnado y él devolver el auto al Tribunal de origen para que , con el debido integración , dictar uno nuevo pronunciamiento ( art . 289 , CPCC ) . el costa él imponer por su orden , dar el índole de el tema debatido ( art. 68 , segundo párrafo , CPCC ) . notifiquer con copia del dictamen de fs . 782787 y devuélva e . eduardo NESTOR de LÁZZARI DANIEL FERNANDO SORIA Luis ESTEBAN GENOUD HILDA KOGAN CARLOS E. CAMPS Secretario\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwT37ulcxl1i"
      },
      "source": [
        "lemas = [word.lemma for sent in doc.sentences for word in sent.words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atWZNzM3xl1s"
      },
      "source": [
        "lemas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO_RLJnQJF9v"
      },
      "source": [
        "# Bibliografia\n",
        "\n",
        "- https://medium.com/@severinperez/exploring-literature-with-the-stanza-nlp-package-927d5b6556bf \n",
        "- https://colab.research.google.com/github/stanfordnlp/stanza/blob/master/demo/Stanza_CoreNLP_Interface.ipynb#scrollTo=ezEjc9LeV2Xs\n",
        "- https://scikit-learn.org/stable/modules/feature_extraction.html \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nd6OoNXI3K-"
      },
      "source": [
        "# Prueba de Trabjo en Corspus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUrph76u8EXZ"
      },
      "source": [
        "fallos = tbfallos['textos_fallo']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC2cS46m8kV8"
      },
      "source": [
        "fallos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxLe6JgU84Uw"
      },
      "source": [
        "fallos = fallos.replace(\"#\",\"\\n\\n\")\n",
        "fallos = fallos.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB9Lg5Id84Uz",
        "outputId": "e8b7c698-cf43-4660-a723-dee20bc5e9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "nlp = stanza.Pipeline(lang='es', processors='tokenize,mwt,pos,lemma', tokenize_no_ssplit=True)\n",
        "doc = nlp(fallos)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 15:18:43 INFO: Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| mwt       | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "=======================\n",
            "\n",
            "2020-10-27 15:18:43 INFO: Use device: gpu\n",
            "2020-10-27 15:18:43 INFO: Loading: tokenize\n",
            "2020-10-27 15:18:43 INFO: Loading: mwt\n",
            "2020-10-27 15:18:43 INFO: Loading: pos\n",
            "2020-10-27 15:18:44 INFO: Loading: lemma\n",
            "2020-10-27 15:18:44 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5nhMWQiRQSh"
      },
      "source": [
        "def print_doc_info(doc):\n",
        "    print(f\"Num sentences:\\t{len(doc.sentences)}\")\n",
        "    print(f\"Num tokens:\\t{doc.num_tokens}\")\n",
        "    print(f\"Num words:\\t{doc.num_words}\")\n",
        "    print(f\"Num entities:\\t{len(doc.entities)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IWKD-jRQSo",
        "outputId": "dac1768d-078e-4f53-e4df-e185757fa306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "print_doc_info(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num sentences:\t47\n",
            "Num tokens:\t2008\n",
            "Num words:\t2013\n",
            "Num entities:\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "729dNgweRgSQ"
      },
      "source": [
        "print(*[f'{word.lemma}' for sent in doc.sentences for word in sent.words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa8LKFdyRiT3"
      },
      "source": [
        "lemas = [word.lemma for sent in doc.sentences for word in sent.words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WqnxoMGsD_3"
      },
      "source": [
        "lemas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzLWMrBoukl-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02teZL6puk6C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Uw41F8ulBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz5QgNZVRiaV"
      },
      "source": [
        "import spacy\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndr1iGtspMGF"
      },
      "source": [
        "word_freq = Counter(lemas)\n",
        "common_words = word_freq.most_common(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC2rKUEApMYy",
        "outputId": "6991b7b5-c0a9-4eff-8bed-b56378a8403d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "common_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('el', 208), ('de', 140), (',', 121), ('.', 79), ('y', 49)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHQAzypsy35G"
      },
      "source": [
        "# Continuar con armado de matriz docxword con STANZA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqiFtF9HzHNP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnRyfiDXUqCl"
      },
      "source": [
        "# Word count Matrix of documents with SKLEARN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNuUSe6CUHIV"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SGqOLvZZsxN",
        "outputId": "e843a9bd-387f-4c69-f96a-56bc5bcd5baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "tbfallos['textos_fallo']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "1      #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "2      #TEXTO COMPLETO#\"VOSS SUSANA BEATRIZ C/ VILLAR...\n",
              "3      #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "4      #TEXTO COMPLETO#\"RICA ARIEL FEDERICO Y OTROS C...\n",
              "                             ...                        \n",
              "909    #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "910    #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "911    #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "912    #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "913    #TEXTO COMPLETO#A C U E R D O#En la ciudad de ...\n",
              "Name: textos_fallo, Length: 914, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIecewEbVZDl"
      },
      "source": [
        "df = tbfallos['textos_fallo']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqEqPaAFUQhc"
      },
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit(df)\n",
        "results = cv.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dct0LYlVdWq",
        "outputId": "6db35391-b68f-45fe-ef42-6d22c6c6938f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(results.shape) # Sparse matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(914, 44226)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fybamPUWm8"
      },
      "source": [
        "features = cv.get_feature_names()\n",
        "df_res = pd.DataFrame(results.toarray(), columns=features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbz-2D0PZCrO",
        "outputId": "21dff581-7e0a-43f3-a814-c72f5c550b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "df_res.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000016</th>\n",
              "      <th>00000018</th>\n",
              "      <th>00000235</th>\n",
              "      <th>00000261</th>\n",
              "      <th>00000262</th>\n",
              "      <th>00000365</th>\n",
              "      <th>0000056</th>\n",
              "      <th>00000565</th>\n",
              "      <th>00000566</th>\n",
              "      <th>00000570</th>\n",
              "      <th>00000602</th>\n",
              "      <th>00000603</th>\n",
              "      <th>00000622</th>\n",
              "      <th>00000673</th>\n",
              "      <th>00000770</th>\n",
              "      <th>00000771</th>\n",
              "      <th>00000833</th>\n",
              "      <th>00001</th>\n",
              "      <th>00002772</th>\n",
              "      <th>00003413</th>\n",
              "      <th>00003417</th>\n",
              "      <th>00003907</th>\n",
              "      <th>00003908</th>\n",
              "      <th>00008571</th>\n",
              "      <th>00009</th>\n",
              "      <th>0001</th>\n",
              "      <th>000156</th>\n",
              "      <th>00018462</th>\n",
              "      <th>0002</th>\n",
              "      <th>000325</th>\n",
              "      <th>0006</th>\n",
              "      <th>000663</th>\n",
              "      <th>000969</th>\n",
              "      <th>0009867</th>\n",
              "      <th>001</th>\n",
              "      <th>001026</th>\n",
              "      <th>001133</th>\n",
              "      <th>...</th>\n",
              "      <th>ítem</th>\n",
              "      <th>ítems</th>\n",
              "      <th>íter</th>\n",
              "      <th>ñamandú</th>\n",
              "      <th>ñata</th>\n",
              "      <th>óbice</th>\n",
              "      <th>óbices</th>\n",
              "      <th>óbito</th>\n",
              "      <th>ómnibus</th>\n",
              "      <th>óntico</th>\n",
              "      <th>óptica</th>\n",
              "      <th>óptima</th>\n",
              "      <th>óptimas</th>\n",
              "      <th>óptimo</th>\n",
              "      <th>órbita</th>\n",
              "      <th>órbitas</th>\n",
              "      <th>órdenes</th>\n",
              "      <th>órgano</th>\n",
              "      <th>órganos</th>\n",
              "      <th>ósea</th>\n",
              "      <th>óseas</th>\n",
              "      <th>óseo</th>\n",
              "      <th>ótico</th>\n",
              "      <th>óvulos</th>\n",
              "      <th>últ</th>\n",
              "      <th>última</th>\n",
              "      <th>últimamente</th>\n",
              "      <th>últimas</th>\n",
              "      <th>últimaáratioádel</th>\n",
              "      <th>último</th>\n",
              "      <th>últimos</th>\n",
              "      <th>única</th>\n",
              "      <th>únicamente</th>\n",
              "      <th>únicas</th>\n",
              "      <th>único</th>\n",
              "      <th>únicos</th>\n",
              "      <th>útero</th>\n",
              "      <th>útil</th>\n",
              "      <th>útiles</th>\n",
              "      <th>útilmente</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44226 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  0000  00000016  00000018  ...  únicos  útero  útil  útiles  útilmente\n",
              "0   0    0     0         0         0  ...       0      0     1       0          0\n",
              "1   0    0     0         0         0  ...       0      0     0       0          0\n",
              "2   0    0     0         0         0  ...       0      0     0       0          0\n",
              "3   0    0     0         0         0  ...       0      0     0       0          0\n",
              "4   0    0     0         0         0  ...       0      0     0       0          0\n",
              "\n",
              "[5 rows x 44226 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    }
  ]
}